---
title: "Lab 4"
author: "Kaz Sakamoto"
date: "4/1/2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, error = FALSE, cache = TRUE, message = FALSE)
```

# K-means clustering

Let's load some packages that we will be using
```{r}
library(GGally)
library(dplyr)
library(ggplot2)
```

we will load our data that we need which comes from the ACS. We have taken four
demographic data points.

- Average Household Size
- Median Household Income
- Median Gross Rent
- Average Commute time in min

```{r}
readr::read_csv("../Data/ACS2016Counties.csv") %>% 
    select(Geo_COUNTY, starts_with("SE")) %>% 
    filter(complete.cases(.))-> counties 

names(counties) <- c("countyID", "AvgHHSize", 
                     "MedHHIncome", "MedGrossRent", "AvgCommute")
```

let's first normalize our data so it's easier to compare.
```{r}
df <- scale(counties[-1]) %>% as.data.frame()
```

Here is a calculation to create a chart of the total within-groups sums of squares against the number of clusters in a K-means solution.
The output will start to look like a curve, and where the bend happens should be where we choose the number of K.
```{r}
kMax <- 13 # Maximal number of clusters
wss <- sapply(1:kMax, 
        function(k){kmeans(df, k)$tot.withinss})

data.frame(wss, clusters = 1:kMax) %>% 
    ggplot(aes(x = clusters, y = wss)) + geom_point() +
    geom_line() + xlab("Number of clusters K") +
       ylab("Total within-clusters sum of squares") + theme_minimal()

```

Here is another method to find the best K for clusters.

```{r}
library(NbClust)
set.seed(222)
nc <- NbClust(df %>% sample_frac(.35), min.nc=2, max.nc=10, method="kmeans")
```

let's check to see which k performed the best

```{r}
table(nc$Best.n[1,])
```

if we plot it out we can see that 2 and 3 are being recommended 

```{r}
barplot(table(nc$Best.n[1,]),
          xlab="Numer of Clusters", ylab="Number of Criteria",
          main="Number of Clusters Chosen by 26 Criteria")
```

running kmeans with 3 clusters

```{r}
kmeans(df, 3) -> k3
```
checking the size and centers of the clusters

```{r}
k3$size
k3$centers
```

adding back labels to our dataset

```{r}
df$cluster <- as.factor(k3$cluster)
```

Let's plot our results

```{r}

ggally_mysmooth <- function(data, mapping, ...){
    ggplot(data = data, mapping=mapping) +
        geom_density(fill=NA)
}

ggpairs(df, 1:4, mapping = ggplot2::aes(color = cluster),
        lower = list(continuous = wrap("points", shape = 1, alpha = .25)),
        diag = list(continuous = ggally_mysmooth))

```

# K Nearest Neighbor

Let's first read in the data
```{r}
 MN <- readr::read_csv("../Data/PLUTO/MN_pluto.csv")
```

Let's take a few columns and Multi-Family Elevator buildings and Industrial/Manufacturing Lots
```{r}
MN %>% select(NumFloors, LotArea, AssessTot, LandUse, XCoord, YCoord) %>% 
    filter(LandUse %in% c(5, 9) & complete.cases(.)) %>% 
    mutate(LandUse = if_else(LandUse == 5, "Comm", "Park")) -> MN

```

Now let's scale our variables

```{r}
MN %>% mutate(NumFloors = scale(NumFloors),
              LotArea = scale(LotArea),
              AssessTot = scale(AssessTot),
              LandUse = as.character(LandUse)) -> MN
```

```{r}
table(MN$LandUse)
```

There is still 5,643 rows which might be too large for our analysis. For ease let's tak a sample fraction
```{r}
MN %>% group_by(LandUse) %>% sample_frac(size = 0.5) %>% ungroup() -> MNSamp
```

Let's visualize what this looks like so far first with as AssessTot and NumFloors

```{r}
ggplot(MNSamp, aes(x = AssessTot, y = NumFloors, color = LandUse)) + geom_point()
```

Let's now take a look at plotting and XCoord and YCoord
```{r}
ggplot(MNSamp, aes(x = XCoord, y = YCoord, color = LandUse)) + geom_point()
```

Now we are going to make the train test split of 70% train, 30% test.

```{r}
smp <- sample(2, nrow(MNSamp), replace=TRUE, prob=c(0.7, 0.3))

```

We will now take  this sample vector and filter through our data
```{r}
trainDF <- MNSamp %>% filter(smp == 1) %>% 
    select(AssessTot, NumFloors)
testDF <-  MNSamp %>% filter(smp == 2) %>% 
    select(AssessTot, NumFloors)

trainLabel <- MNSamp %>% filter(smp == 1) %>% 
    select(LandUse)
testLabel <- MNSamp %>% filter(smp == 2) %>% 
    select(LandUse)
```

```{r}
library(class)
dfPred <- knn(trainDF, testDF, trainLabel$LandUse, k = 9)
```

```{r}
library(gmodels)
CrossTable(testLabel$LandUse,dfPred,prop.chisq = F)
```

```{r}
testDF %>% bind_cols(testLabel) %>% 
    mutate(pred = dfPred) %>% 
    mutate(test = if_else(pred == LandUse, "Correct", "Wrong")) -> output
```

```{r, cache = FALSE}
ggplot(output, aes(x = AssessTot, y = NumFloors, color = test)) + geom_point() +
    facet_wrap( ~ LandUse)
```

Let's try with x and y coordinates

```{r}
trainCoordDF <- MNSamp %>% filter(smp == 1) %>% 
    select(XCoord, YCoord)
testCoordDF <-  MNSamp %>% filter(smp == 2) %>% 
    select(XCoord, YCoord)

trainLabel <- MNSamp %>% filter(smp == 1) %>% 
    select(LandUse)
testLabel <- MNSamp %>% filter(smp == 2) %>% 
    select(LandUse)
```

```{r}
library(class)
dfCoordPred <- knn(trainCoordDF, testCoordDF, trainLabel$LandUse, k = 9)
```

```{r}
library(gmodels)
CrossTable(testLabel$LandUse,dfCoordPred,prop.chisq = F)
```


```{r}
testCoordDF %>% bind_cols(testLabel) %>% 
    mutate(pred = dfCoordPred) %>% 
    mutate(test = if_else(pred == LandUse, "Correct", "Wrong")) -> output
```

```{r, cache = FALSE}
ggplot(output, aes(x = XCoord, y = YCoord, color = test)) + geom_point() +
    facet_wrap( ~ LandUse)
```


